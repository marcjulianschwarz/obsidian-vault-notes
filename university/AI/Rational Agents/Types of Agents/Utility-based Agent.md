---
uni-module: "AI"
---
# Utility-based Agent

An [[Rational Agent|Agent]] (similar to [[Goal-based Agent]]) which has a **world model** and a **utility function** that models its preferences among the states of that world.
It chooses the [[Action]] that leads to the **best [[Expected Utility]]**.

A [[Utility-based Agent]] is more general than a [[Goal-based Agent]] as we can always force it to follow only one goal by rewarding only goal states in the utility function.

Utility based agents add a tradeoff between goals to make rational decisions in a conflicting situation.

## Schema

![[Bildschirm­foto 2022-12-07 um 18.44.59.png]]

## Further

→ [[Learning Agent]]
